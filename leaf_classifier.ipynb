{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cheap-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liable-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: acer_campestre\n",
      "Done\n",
      "Processing: acer_palmatum\n",
      "Done\n",
      "Processing: betula_alleghaniensis\n",
      "Done\n",
      "Processing: betula_jacqemontii\n",
      "Done\n",
      "Processing: carya_glabra\n",
      "Done\n",
      "Processing: celtis_occidentalis\n",
      "Done\n",
      "Processing: cercis_canadensis\n",
      "Done\n",
      "Processing: cornus_florida\n",
      "Done\n",
      "Processing: crataegus_crus-galli\n",
      "Done\n",
      "Processing: fagus_grandifolia\n",
      "Done\n",
      "Processing: ginkgo_biloba\n",
      "Done\n",
      "Processing: halesia_tetraptera\n",
      "Done\n",
      "Processing: ilex_opaca\n",
      "Done\n",
      "Processing: liquidambar_styraciflua\n",
      "Done\n",
      "Processing: magnolia_soulangiana\n",
      "Done\n",
      "Processing: malus_pumila\n",
      "Done\n",
      "Processing: morus_rubra\n",
      "Done\n",
      "Processing: ostrya_virginiana\n",
      "Done\n",
      "Processing: platanus_acerifolia\n",
      "Done\n",
      "Processing: populus_grandidentata\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import skimage.data as data\n",
    "import skimage.color as color\n",
    "import skimage\n",
    "import skimage.measure as measure\n",
    "from skimage.morphology import square\n",
    "import skimage.morphology\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "d = {}\n",
    "\n",
    "def process_directory(directory):\n",
    "    \"\"\"\n",
    "    Process dricetory - dir with images is nested, there is main dir and within there are dirs with leafs species.\n",
    "    This function saves all species dirs from main dir to list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str\n",
    "        Main directory to be processed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dirs\n",
    "        List of species dirs.\n",
    "    \"\"\"\n",
    "    dirs = []\n",
    "    for dir in os.listdir(directory):\n",
    "        if os.path.isdir(os.path.join(directory, dir)):\n",
    "            dirs.append(dir)\n",
    "    \n",
    "    return dirs\n",
    "\n",
    "\n",
    "def preprocess_img(img):\n",
    "    \"\"\"\n",
    "    Makes images preprocessing:\n",
    "        - changes images to black and white spectrum,\n",
    "        - removes noise,\n",
    "        - makes image dilatation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : skimage.io object\n",
    "        Image to be preprocessed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mask\n",
    "        Image mask used in the next stage.\n",
    "    \"\"\"\n",
    "    imgg = color.rgb2gray(img)\n",
    "    mask = (imgg < 0.5)\n",
    "    mask = skimage.morphology.dilation(mask, square(3))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_leaf(mask):\n",
    "    \"\"\"\n",
    "    Extracts leaf from image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : np.array\n",
    "        Image from which leaf will be extracted.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array : leaf.\n",
    "    int : leaf's area.\n",
    "    int : number of pixels of convex hull image, which is the smallest convex polygon that encloses the region.\n",
    "    int : the diameter of a circle with the same area as the region.\n",
    "    \"\"\"\n",
    "    labels = measure.label(mask)\n",
    "    props = skimage.measure.regionprops(labels)\n",
    "    areas = np.array([(i, props[i]['area']) for i in range(1, labels.max()) if props[i]['area'] > 1000])\n",
    "    minimal = 0\n",
    "    pos = 0\n",
    "    for pair in areas:\n",
    "        distance = sum(props[pair[0]]['centroid']) - 800\n",
    "        if minimal == 0 or distance < minimal:\n",
    "            minimal = distance\n",
    "            pos = pair[0]\n",
    "\n",
    "    return props[pos]['image'], props[pos]['area'], props[pos]['convex_area'], np.rint(props[pos]['equivalent_diameter'])\n",
    "\n",
    "\n",
    "def calculate_tail_area(img):\n",
    "    \"\"\"\n",
    "    Calculates area of leaf's tail.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.array\n",
    "        Numpy array of image from which tail area will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int : Tail's area of given leaf.\n",
    "    \"\"\"\n",
    "    imgg = skimage.morphology.erosion(img, square(5))\n",
    "    imgg = img ^ imgg\n",
    "    imgg = skimage.morphology.binary_opening(imgg, square(3))\n",
    "    \n",
    "    tmp_labels = measure.label(imgg)\n",
    "    tmp_props = skimage.measure.regionprops(tmp_labels)\n",
    "    try:\n",
    "        return int(max([tmp_props[i]['area'] for i in range(0, tmp_labels.max())]))\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def calculate_perimeter(img):\n",
    "    \"\"\"\n",
    "    Calculates leaf perimeter.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.array\n",
    "        Numpy array of image which perimeter will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int : Perimeter of leaf.\n",
    "    \"\"\"\n",
    "    img = skimage.morphology.binary_opening(img, square(5))\n",
    "    tmp_labels = measure.label(img)\n",
    "    tmp_props = skimage.measure.regionprops(tmp_labels)\n",
    "    return int(sum([tmp_props[i]['perimeter'] for i in range(0, tmp_labels.max())]))\n",
    "\n",
    "\n",
    "def calculate_skeleton(img):\n",
    "    \"\"\"\n",
    "    Calculates leaf's skeleton.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.array\n",
    "        Numpy array of image which skeleton will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int : Sum of pixels in leaf's skeleton.\n",
    "    \"\"\"\n",
    "    return int(np.sum(skimage.morphology.skeletonize(img)))\n",
    "\n",
    "\n",
    "def calculate_major_axis_length(img):\n",
    "    \"\"\"\n",
    "    Calculates the length of major axis of leaf.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.array\n",
    "        Numpy array of image which major axis will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int : Leaf's major axis length.\n",
    "    \"\"\"\n",
    "    img = skimage.morphology.binary_opening(img, square(5))\n",
    "    tmp_labels = measure.label(img)\n",
    "    tmp_props = skimage.measure.regionprops(tmp_labels)\n",
    "    return int(max([tmp_props[i]['major_axis_length'] for i in range(0, tmp_labels.max())]))\n",
    "\n",
    "\n",
    "def calculate_minor_axis_length(img):\n",
    "    \"\"\"\n",
    "    Calculates the length of minor axis of leaf.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.array\n",
    "        Numpy array of image which minor axis will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int : Leaf's minor axis length.\n",
    "    \"\"\"\n",
    "    img = skimage.morphology.binary_opening(img, square(5))\n",
    "    tmp_labels = measure.label(img)\n",
    "    tmp_props = skimage.measure.regionprops(tmp_labels)\n",
    "    return int(max([tmp_props[i]['minor_axis_length'] for i in range(0, tmp_labels.max())]))\n",
    "\n",
    "\n",
    "def calculate_mean_distance_from_center(img):\n",
    "    \"\"\"\n",
    "    Calculates the mean distance of each contour point from the center of the leaf.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.array\n",
    "        Numpy array of image which mean distance of all contour points will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int : Mean distance of all contour points from the center of the leaf.\n",
    "    \"\"\"\n",
    "    img = skimage.morphology.binary_opening(img, square(5))\n",
    "    contour = skimage.measure.find_contours(img)\n",
    "    \n",
    "    labels = measure.label(img)\n",
    "    props = skimage.measure.regionprops(labels)\n",
    "\n",
    "    areas = np.array([(i, props[i]['area']) for i in range(1, labels.max()) if props[i]['area'] > 1000])\n",
    "    maximal = 0\n",
    "    pos = 0\n",
    "    for pair in areas:\n",
    "        if maximal == 0 or pair[1] > maximal:\n",
    "            maximal = pair[1]\n",
    "            pos = pair[0]\n",
    "    \n",
    "    center = np.array(props[pos]['centroid'])\n",
    "    contour[0] -= center\n",
    "    return int(np.rint(np.mean(contour[0])))\n",
    "\n",
    "\n",
    "def save_to_dict(mask, dir, it):\n",
    "    \"\"\"\n",
    "    Calls functions which calculates leaf's properties and saves results to dictionary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : np.array\n",
    "        Mask returned by preprocess_img function.\n",
    "    dir : str\n",
    "        Directory name with given species.\n",
    "    it : int\n",
    "        Image number.\n",
    "    \"\"\"\n",
    "    img, area, convex_area, equivalent_diameter = get_leaf(mask)\n",
    "    d[dir][it]['area'] = int(area)\n",
    "    d[dir][it]['convex_area'] = int(convex_area)\n",
    "    d[dir][it]['equivalent_diameter'] = int(equivalent_diameter)\n",
    "    d[dir][it]['tail_area'] = calculate_tail_area(img)\n",
    "    d[dir][it]['perimeter'] = calculate_perimeter(img)\n",
    "    d[dir][it]['skeleton'] = calculate_skeleton(img)\n",
    "    d[dir][it]['major_axis_length'] = calculate_major_axis_length(img)\n",
    "    d[dir][it]['minor_axis_length'] = calculate_minor_axis_length(img)\n",
    "    d[dir][it]['mean_distance_from_center'] = calculate_mean_distance_from_center(img)\n",
    "\n",
    "\n",
    "def save_dict(file_name):\n",
    "    \"\"\"\n",
    "    Saves results of images processing to file in JSON fomrat.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        Name of file to which data will be saved.\n",
    "    \"\"\"\n",
    "    with open(file_name + '.json', 'w') as f:\n",
    "        json.dump(d, f, indent=4)\n",
    "\n",
    "\n",
    "def process_single_species(dir):\n",
    "    \"\"\"\n",
    "    Calls preprocessing fuction for images in given directory and then calls save_to_dict function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir : str\n",
    "        Name of directory which images will be processed.\n",
    "    \"\"\"\n",
    "    for i in os.listdir():\n",
    "        d[dir] = {}\n",
    "\n",
    "    for it, file in enumerate(os.listdir()):\n",
    "        d[dir][it] = {}\n",
    "        img = io.imread(file)\n",
    "        mask = preprocess_img(img)\n",
    "        save_to_dict(mask, dir, it)\n",
    "\n",
    "\n",
    "def process_files(main_dir, dirs_lst):\n",
    "    \"\"\"\n",
    "    Process main directory and calls process_single_species function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    main_dir : str\n",
    "        Name of main dir to be processed.\n",
    "    dirs_lst : list\n",
    "        List of directories with leafs species.\n",
    "    \"\"\"\n",
    "    os.chdir(main_dir)\n",
    "\n",
    "    for dir in dirs_lst:\n",
    "        print('Processing: ' + dir)\n",
    "        os.chdir(dir)\n",
    "        process_single_species(dir)\n",
    "        os.chdir('..')\n",
    "        print('Done')\n",
    "    \n",
    "    os.chdir('..')\n",
    "\n",
    "\n",
    "dirs = process_directory('leafsnap-subset1')\n",
    "process_files('leafsnap-subset1', dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "romantic-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "svm_clf = svm.SVC()\n",
    "gnb = GaussianNB()\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "random_forest_clf = RandomForestClassifier()\n",
    "sgdc_clf = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "passive-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_array():\n",
    "    \"\"\"\n",
    "    Creates data, target and target names arrays.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : np.array\n",
    "        Array of values for all calculated leafs properties.\n",
    "    target : np.array\n",
    "        Array of numbers which corresponds to leafs species.\n",
    "    target_names : np.array\n",
    "        Array of names of leafs species.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    target = []\n",
    "    target_names = np.array([key for key in d.keys()])\n",
    "    for pos, key in enumerate(d):\n",
    "        for it in d[key]:\n",
    "            tmp_data = []\n",
    "            target.append(pos)\n",
    "            for param in d[key][it]:\n",
    "                tmp_data.append(d[key][it][param])\n",
    "            data.append(np.array(tmp_data))\n",
    "    \n",
    "    data = np.array(data)\n",
    "    target = np.array(target)\n",
    "    \n",
    "    return data, target, target_names\n",
    "\n",
    "def count_mistakes(current, real):\n",
    "    difference = current - real\n",
    "    return len(difference[difference != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "binding-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target, target_names = create_data_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ancient-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_fit(data, target):\n",
    "    \"\"\"\n",
    "    Calculates mean fit for all classificators.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array\n",
    "        Array of values for all calculated leafs properties.\n",
    "    target : np.array\n",
    "        Array of numbers which corresponds to leafs species.\n",
    "    \"\"\"\n",
    "    knn_lst = []\n",
    "    svm_lst = []\n",
    "    sgdc_lst = []\n",
    "    gnb_lst = []\n",
    "    tree_lst = []\n",
    "    random_forest_lst = []\n",
    "\n",
    "    for i in range(100):\n",
    "        knn = KNeighborsClassifier()\n",
    "        svm_clf = svm.SVC()\n",
    "        gnb = GaussianNB()\n",
    "        tree_clf = tree.DecisionTreeClassifier()\n",
    "        random_forest_clf = RandomForestClassifier()\n",
    "        sgdc_clf = SGDClassifier()\n",
    "\n",
    "        indices = np.random.permutation(len(data))\n",
    "        train_X = data[indices[:-100]]\n",
    "        train_Y = target[indices[:-100]]\n",
    "        test_X = data[indices[-100:]]\n",
    "        test_Y = target[indices[-100:]]\n",
    "        \n",
    "        knn.fit(train_X, train_Y)\n",
    "        svm_clf.fit(train_X, train_Y)\n",
    "        sgdc_clf.fit(train_X, train_Y)\n",
    "        gnb.fit(train_X, train_Y)\n",
    "        tree_clf.fit(train_X, train_Y)\n",
    "        random_forest_clf.fit(train_X, train_Y)\n",
    "        \n",
    "        knn_lst.append((len(test_X) - count_mistakes(knn.predict(test_X), test_Y)) / len(test_X))\n",
    "        svm_lst.append((len(test_X) - count_mistakes(svm_clf.predict(test_X), test_Y)) / len(test_X))\n",
    "        sgdc_lst.append((len(test_X) - count_mistakes(sgdc_clf.predict(test_X), test_Y)) / len(test_X))\n",
    "        gnb_lst.append((len(test_X) - count_mistakes(gnb.predict(test_X), test_Y)) / len(test_X))\n",
    "        tree_lst.append((len(test_X) - count_mistakes(tree_clf.predict(test_X), test_Y)) / len(test_X))\n",
    "        random_forest_lst.append((len(test_X) - count_mistakes(random_forest_clf.predict(test_X), test_Y)) / len(test_X))\n",
    "                                 \n",
    "    print('Correct percent for KNN: ' + str(round(np.mean(knn_lst), 2)) + '%')\n",
    "    print('Correct percent for SVM: ' + str(round(np.mean(svm_lst), 2)) + '%')\n",
    "    print('Correct percent for SGDC: ' + str(round(np.mean(sgdc_lst), 2)) + '%')\n",
    "    print('Correct percent for GNB: ' + str(round(np.mean(gnb_lst), 2)) + '%')\n",
    "    print('Correct percent for TREE: ' + str(round(np.mean(tree_lst), 2)) + '%')\n",
    "    print('Correct percent for RANDOM FOREST: ' + str(round(np.mean(random_forest_lst), 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "painful-accused",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct percent for KNN: 0.51%\n",
      "Correct percent for SVM: 0.28%\n",
      "Correct percent for SGDC: 0.09%\n",
      "Correct percent for GNB: 0.44%\n",
      "Correct percent for TREE: 0.65%\n",
      "Correct percent for RANDOM FOREST: 0.78%\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "american-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "super-mortality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alpha-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "low_variance_removed_data = sel.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "surface-oxford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_variance_removed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "described-round",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4103ac5e061a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munivariate__feature_selection_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# chi2 test rquieres non-negative values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\anaconda\\envs\\po\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\po\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mscore_func_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\po\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mchi2\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "univariate__feature_selection_data = SelectKBest(chi2, k=4).fit_transform(data, target) # chi2 test rquieres non-negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ordered-clone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=150)\n",
    "clf = clf.fit(data, target)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(data)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exclusive-tumor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct percent for KNN: 0.27%\n",
      "Correct percent for SVM: 0.17%\n",
      "Correct percent for SGDC: 0.06%\n",
      "Correct percent for GNB: 0.37%\n",
      "Correct percent for TREE: 0.64%\n",
      "Correct percent for RANDOM FOREST: 0.74%\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_fit(X_new, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mounted-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "undefined-nation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "olive-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "corporate-scout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "defined-danger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 50,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "otherwise-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, target):\n",
    "    \"\"\"\n",
    "    Evaluate process of classification.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        Classificator to be evaluated.\n",
    "    data : np.array\n",
    "        Array of values for all calculated leafs properties.\n",
    "    target : np.array\n",
    "        Array of numbers which corresponds to leafs species.\n",
    "    \"\"\"\n",
    "    random_forest_lst = []\n",
    "    \n",
    "    indices = np.random.permutation(len(data))\n",
    "    train_X = data[indices[:-100]]\n",
    "    train_Y = target[indices[:-100]]\n",
    "    test_X = data[indices[-100:]]\n",
    "    test_Y = target[indices[-100:]]\n",
    "\n",
    "    model.fit(train_X, train_Y)\n",
    "\n",
    "    random_forest_lst.append((len(test_X) - count_mistakes(model.predict(test_X), test_Y)) / len(test_X))\n",
    "\n",
    "    print('Correct percent: ' + str(round(np.mean(random_forest_lst), 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "buried-leader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct percent: 0.77%\n"
     ]
    }
   ],
   "source": [
    "evaluate(rf_random.best_estimator_, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fiscal-adelaide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct percent: 0.85%\n"
     ]
    }
   ],
   "source": [
    "evaluate(random_forest_clf, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "accessible-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 40, 100],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'n_estimators': [500, 1000, 1500, 2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "intimate-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "colored-circulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [10, 20, 40, 100],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 4, 6],\n",
       "                         'n_estimators': [500, 1000, 1500, 2000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "independent-evolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 100,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "illegal-criterion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct percent: 0.74%\n"
     ]
    }
   ],
   "source": [
    "evaluate(grid_search.best_estimator_, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "limiting-pottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct percent: 0.81%\n"
     ]
    }
   ],
   "source": [
    "evaluate(random_forest_clf, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sexual-soccer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_file.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid_search.best_estimator_, 'clf_file.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "seasonal-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = load('clf_file.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "instant-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct percent: 0.86%\n"
     ]
    }
   ],
   "source": [
    "evaluate(rf, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-mills",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
